{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os \n",
    "import pathlib\n",
    "from glob import glob\n",
    "from re import search\n",
    "\n",
    "from osgeo import gdal # type: ignore\n",
    "import rasterio as rs \n",
    "from rasterio.windows import Window\n",
    "from rasterio.transform import xy\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.windows import Window\n",
    "from rasterio import open \n",
    "\n",
    "from pyproj import Transformer\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from numpy import array,meshgrid,arange,log\n",
    "from shapely import box\n",
    "\n",
    "\n",
    "import ibis as ib\n",
    "ib.options.interactive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With dask\n",
    "\n",
    "import dask as dk\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "# import dask_image as dki\n",
    "import xarray as xr\n",
    "import rioxarray as rx\n",
    "\n",
    "from pyarrow import float16,float32,schema,field,uint16,table,Table\n",
    "from pyarrow.parquet import ParquetWriter\n",
    "import pyarrow as pya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_file = \"/Users/cenv1069/Documents/data/datasets/JRC/GHS_BUILT_S_NRES_E2018_GLOBE_R2023A_54009_10_V1_0/GHS_BUILT_S_NRES_E2018_GLOBE_R2023A_54009_10_V1_0.tif\"\n",
    "\n",
    "# big file\n",
    "# src_file=\"/Users/cenv1069/Documents/data/datasets/JRC/GHS_BUILT_C_MSZ_E2018_GLOBE_R2023A_54009_10_V1_0_R8_C19/GHS_BUILT_C_MSZ_E2018_GLOBE_R2023A_54009_10_V1_0_R8_C19.tif\"\n",
    "# big file\n",
    "# src_file = \"/Users/cenv1069/Documents/data/datasets/mining/Global_mining/v2/global_miningarea_v2_30arcsecond.tif\"\n",
    "\n",
    "# src_file = \"/Users/cenv1069/Documents/data/datasets/JRC/S_10m/GHS_BUILT_S_NRES_E2018_GLOBE_R2023A_54009_10_V1_0_R8_C19/GHS_BUILT_S_NRES_E2018_GLOBE_R2023A_54009_10_V1_0_R8_C19.tif\"\n",
    "\n",
    "# src_file = \"/Users/cenv1069/Documents/data/datasets/JRC/S_100m/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19.tif\"\n",
    "# \n",
    "# src_file = \"Users/cenv1069/Documents/data/datasets/JRC/S_100m/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R9_C19/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R9_C19.tif\"\n",
    "\n",
    "# smaller size file\n",
    "# src_file=\"/Users/cenv1069/Documents/data/datasets/JRC/S_1000m/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R8_C19/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R8_C19.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path=\"/Users/cenv1069/Documents/agriculture/mapspam/spam2017v2r1_ssa_yield\"\n",
    "if in_path[len(in_path)-1]!= '/':\n",
    "    in_path=in_path+'/'\n",
    "in_paths = [x for x in glob(in_path + \"**\", recursive=True) if search(pattern = r\"(.ti[f]{1,2}$)|(.nc$)\", string = x)]\n",
    "in_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working workflows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# inspired by : https://rasterio.readthedocs.io/en/stable/topics/virtual-warping.html\n",
    "\n",
    "dst_crs = CRS.from_epsg(4326)\n",
    "print(dst_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lon: float\n",
       "lat: float\n",
       "band_var: float\n",
       "-- schema metadata --\n",
       "lon: 'Longitude coordinate'\n",
       "lat: 'Latitude coordinate'\n",
       "band_var: 'Value associated'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrt_options = {\n",
    "    # 'resampling': Resampling.cubic,\n",
    "    'crs': dst_crs,\n",
    "    # 'transform': dst_transform,\n",
    "    # 'height': dst_height,\n",
    "    # 'width': dst_width,\n",
    "}\n",
    "\n",
    "out_path_vrt = \"test_med.parquet\"\n",
    "\n",
    "rast_schema = schema([('lon',float32())\n",
    "                    ,('lat',float32())\n",
    "                    ,('band_var',float32())\n",
    "                    ])\n",
    "\n",
    "rast_schema.with_metadata({\n",
    "        \"lon\" : \"Longitude coordinate\",\n",
    "        \"lat\" : \"Latitude coordinate\",\n",
    "        \"band_var\" : \"Value associated\",\n",
    "                            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a virtual Warper and windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_med.parquet'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path_vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800000, 3608200)\n",
      "Detected source crs :  ESRI:54009\n",
      "No data value :  (255.0,)\n",
      "(1, 128, 512)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:27\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with ParquetWriter(out_path_vrt, rast_schema) as writer:\n",
    "    with rs.open(src_file) as src:\n",
    "        print(src.shape)\n",
    "        # raise\n",
    "        src_crs = src.crs\n",
    "        if len(src.nodatavals)>1:\n",
    "            nodata = src.nodatavals[0]\n",
    "        else :\n",
    "            nodata = src.nodatavals\n",
    "\n",
    "        print(\"Detected source crs : \", src_crs)\n",
    "        print(\"No data value : \", nodata)\n",
    "\n",
    "        with WarpedVRT(src, **vrt_options) as vrt:\n",
    "            # At this point 'vrt' is a full dataset with dimensions,\n",
    "            # CRS, and spatial extent matching 'vrt_options'.\n",
    "            # Read all data into memory.\n",
    "            # data = vrt.read()\n",
    "            # Process the dataset in chunks.  Likely not very efficient.\n",
    "            \n",
    "            win_transfrom = vrt.window_transform\n",
    "\n",
    "            for _, window in vrt.block_windows():\n",
    "                # print(src.crs)\n",
    "                band1 = vrt.read(window=window)\n",
    "\n",
    "                height = band1.shape[1]\n",
    "                width = band1.shape[2]\n",
    "                cols, rows = meshgrid(arange(width), arange(height))\n",
    "\n",
    "                xs, ys = xy(\n",
    "                    transform = win_transfrom(window),\n",
    "                    rows=rows,\n",
    "                    cols=cols)\n",
    "\n",
    "                lons = array(xs)\n",
    "                lats = array(ys)\n",
    "                \n",
    "                out = DataFrame({\"band_var\" : array(band1).flatten()\n",
    "                                        ,'lon': lons.flatten()\n",
    "                                        ,'lat': lats.flatten()})\n",
    "                \n",
    "                out.drop(index=out.loc[out.band_var==nodata].index,inplace=True)\n",
    "                out.drop(index=out.loc[out.band_var<=0].index,inplace=True)\n",
    "                # print(out.shape)\n",
    "                # print(out.head())\n",
    "\n",
    "                if out.shape[0]!=0:\n",
    "                    writer.write_table(Table.from_pandas(df=out,schema = rast_schema,preserve_index=False,safe=True))\n",
    "\n",
    "            # # # Dump the aligned data into a new file.  A VRT representing\n",
    "            # # # this transformation can also be produced by switching\n",
    "            # # # to the VRT driver.\n",
    "            # # directory, name = os.path.split(path)\n",
    "            # # outfile = os.path.join(directory, 'aligned-{}'.format(name))\n",
    "            # # rio_shutil.copy(vrt, outfile, driver='GTiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a classic window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "with ParquetWriter(out_path_vrt, rast_schema) as writer:\n",
    "        with rs.open(src_file) as src:\n",
    "            \n",
    "            src_crs = src.crs\n",
    "            win_transfrom = src.window_transform\n",
    "            \n",
    "            transformer = Transformer.from_crs(str(src_crs), 'EPSG:4326', always_xy=True)\n",
    "            \n",
    "            if len(src.nodatavals)>1:\n",
    "                nodata = src.nodatavals[0]\n",
    "            else :\n",
    "                nodata = src.nodatavals\n",
    "\n",
    "            print(\"No data value : \", nodata)\n",
    "            print(\"Detected source crs : \", src_crs)\n",
    "            \n",
    "            # Process the dataset in chunks.  Likely not very efficient.\n",
    "            for ij, window in src.block_windows():\n",
    "                # print(window)\n",
    "                # print(src.crs)\n",
    "                band1 = src.read(window=window)\n",
    "                # print(band1[0])\n",
    "                height = band1.shape[1]\n",
    "                width = band1.shape[2]\n",
    "                cols, rows = meshgrid(arange(width), arange(height))\n",
    "                # print(win_transfrom(window))\n",
    "                xs, ys = xy(\n",
    "                    transform = win_transfrom(window),\n",
    "                    rows=rows,\n",
    "                    cols=cols)\n",
    "                \n",
    "                # print(xs,ys)\n",
    "                \n",
    "                lons,lats = transformer.transform(array(xs),array(ys))\n",
    "                # print(lons.shape)\n",
    "                # print(lats.shape)\n",
    "                # print(len(array(band1).flatten()))\n",
    "                # print(len(lons.flatten()))\n",
    "                \n",
    "                out = DataFrame({'lon': lons.flatten(),\n",
    "                                    'lat': lats.flatten(),\n",
    "                                    \"band_var\" : array(band1[0,:,:]).flatten(),\n",
    "                                    })\n",
    "                \n",
    "                out.drop(index=out.loc[out.band_var==nodata].index,inplace=True)\n",
    "                out.drop(index=out.loc[out.band_var<=0].index,inplace=True)\n",
    "                \n",
    "                # print(out.shape)\n",
    "                # print(out.head())\n",
    "                \n",
    "                if out.shape[0]!=0:\n",
    "                        writer.write_table(Table.from_pandas(df=out,schema = rast_schema,preserve_index=False,safe=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ib.read_parquet(out_path_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.count())\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.band_var.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.select(\"lon\",\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_xy = test_data.select(\"lon\",\"lat\").to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpd.GeoSeries(gpd.points_from_xy(test_xy[\"lon\"],test_xy[\"lat\"],crs=\"epsg:4326\")).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = src_file\n",
    "include = False\n",
    "\n",
    "out_path_cwin = f\"rast_convert_cwin.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with ParquetWriter(out_path_cwin, rast_schema) as writer:\n",
    "    with rs.open(src_file) as src:\n",
    "        \n",
    "        src_crs = src.crs\n",
    "        if len(src.nodatavals)>1:\n",
    "            nodata = src.nodatavals[0]\n",
    "        else :\n",
    "            nodata = src.nodatavals\n",
    "\n",
    "        print(\"No data value : \", nodata)\n",
    "        print(\"Detected source crs : \", src_crs)\n",
    "\n",
    "        with WarpedVRT(src, **vrt_options) as vrt:\n",
    "            # At this point 'vrt' is a full dataset with dimensions,\n",
    "            # CRS, and spatial extent matching 'vrt_options'.\n",
    "            # Read all data into memory.\n",
    "            # data = vrt.read()\n",
    "            # Process the dataset in chunks.  Likely not very efficient.\n",
    "            \n",
    "            win_transfrom = vrt.window_transform\n",
    "\n",
    "            print(vrt.shape)\n",
    "\n",
    "            # select window size \n",
    "            win_ratio = vrt.shape[0]/vrt.shape[1]\n",
    "            win_width = int(np.min([vrt.shape[1],3500]))\n",
    "            win_height = int(win_width*win_ratio)\n",
    "\n",
    "            win_w = int(vrt.shape[1]/win_width)\n",
    "            win_h = int(vrt.shape[0]/win_height)\n",
    "\n",
    "            for (i,j) in itertools.product(range(win_w+1),range(win_h+1)):\n",
    "                \n",
    "                if i==win_w:\n",
    "                    width = vrt.shape[1]-win_w*win_width\n",
    "                else : \n",
    "                    width = win_width\n",
    "                \n",
    "                if j==win_h:\n",
    "                    height = vrt.shape[0]-win_h*win_height\n",
    "                else : \n",
    "                    height = win_height\n",
    "            \n",
    "                window = Window(col_off=i*win_width,row_off=j*win_height,width=width,height=height)\n",
    "                \n",
    "                band1 = vrt.read(window=window)\n",
    "                \n",
    "                # height = band1.shape[1]\n",
    "                # width = band1.shape[2]\n",
    "                cols, rows = meshgrid(arange(width), arange(height))\n",
    "\n",
    "                xs, ys = xy(\n",
    "                    transform = win_transfrom(window),\n",
    "                    rows=rows,\n",
    "                    cols=cols)\n",
    "\n",
    "                lons = array(xs)\n",
    "                lats = array(ys)\n",
    "                \n",
    "                out = DataFrame({\"band_var\" : array(band1).flatten()\n",
    "                                        ,'lon': lons.flatten()\n",
    "                                        ,'lat': lats.flatten()})\n",
    "                \n",
    "                out.drop(index=out.loc[out.band_var==nodata].index,inplace=True)\n",
    "                out.drop(index=out.loc[out.band_var<=0].index,inplace=True)\n",
    "                # print(out.shape)\n",
    "                # print(out.head())\n",
    "\n",
    "                if out.shape[0]!=0:\n",
    "                    writer.write(Table.from_pandas(df=out,schema = rast_schema,preserve_index=False,safe=True))\n",
    "            \n",
    "        # # # Dump the aligned data into a new file.  A VRT representing\n",
    "        # # # this transformation can also be produced by switching\n",
    "        # # # to the VRT driver.\n",
    "        # # directory, name = os.path.split(path)\n",
    "        # # outfile = os.path.join(directory, 'aligned-{}'.format(name))\n",
    "        # # rio_shutil.copy(vrt, outfile, driver='GTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vrt = ib.read_parquet(out_path_vrt)\n",
    "test_cwin = ib.read_parquet(out_path_cwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vrt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cwin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.difference(test_vrt,test_cwin).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a huge file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the module from the script\n",
    "! python ../../src/scalenav/rast_converter.py /Users/cenv1069/Documents/data/datasets/JRC/S_100m/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19.tif ../../test_big.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the module from the build package \n",
    "! python -m scalenav.rast_converter /Users/cenv1069/Documents/data/datasets/JRC/S_100m/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19/GHS_BUILT_S_NRES_E2015_GLOBE_R2023A_54009_100_V1_0_R8_C19.tif ../../test_big.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a huge processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ib.connect(\"duckdb://\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = conn.read_parquet('/Users/cenv1069/Documents/data/datasets/JRC/H_AGBH_100.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.band_var.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rs.open(\"/Users/cenv1069/Documents/data/datasets/JRC/S_1000m/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R7_C22/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R7_C22.tif\") as src:\n",
    "#     # Process the dataset in chunks.  Likely not very efficient.\n",
    "#     print(src.height)\n",
    "#     print(src.width)\n",
    "    \n",
    "#     for ij, window in src.block_windows():\n",
    "#         print((ij, window))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def process_data():\n",
    "    # Simulate data processing loop\n",
    "    for _ in tqdm(range(100), desc=\"Processing data...\"):\n",
    "        time.sleep(0.1)  # Simulating some processing time for each iteration\n",
    "\n",
    "def show_clock():\n",
    "    with tqdm(total=0, bar_format=\"{desc}\", dynamic_ncols=True) as pbar:\n",
    "        while True:\n",
    "            # Get current time\n",
    "            now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            # Update the tqdm bar with the current time\n",
    "            pbar.set_description(f\"Clock: {now}\")\n",
    "            time.sleep(1)  # Update every second\n",
    "\n",
    "\n",
    "# Run the clock in the background\n",
    "import threading\n",
    "clock_thread = threading.Thread(target=show_clock, daemon=True)\n",
    "clock_thread.start()\n",
    "\n",
    "# Run the data processing function\n",
    "process_data()\n",
    "\n",
    "# Optionally, wait for the clock thread to finish if needed\n",
    "clock_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDAL translate\n",
    "slow af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_file = \"/Users/cenv1069/Documents/data/datasets/JRC/S_1000m/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R8_C19/GHS_BUILT_S_NRES_E2020_GLOBE_R2023A_54009_1000_V1_0_R8_C19.tif\"\n",
    "# # Open the GeoTIFF File:\n",
    "# dataset = gdal.Open(src_file)\n",
    "# # Convert GeoTIFF to XYZ Format:\n",
    "# gdal.Translate('output.xyz', dataset, format='XYZ')\n",
    "# # Read XYZ into Pandas DataFrame:\n",
    "# df = pd.read_csv('output.xyz', sep=' ', header=None, names=['x', 'y', 'value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = False\n",
    "num_workers = 3\n",
    "out_fold = \"results\"\n",
    "if not os.path.exists(out_fold):\n",
    "    # os.rmdir(out_fold)\n",
    "    os.mkdir(out_fold)\n",
    "out_path = f\"rast_convert_par_{num_workers}.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = [out_fold + \"/\" + out_fold + \"_\" + str(i) + \".parquet\" for i in range(num_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/results_0.parquet',\n",
       " 'results/results_1.parquet',\n",
       " 'results/results_2.parquet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected source crs :  ESRI:54009\n",
      "No data value :  (65535.0,)\n",
      "Processing!\n",
      "Processing!\n",
      "Processing!\n"
     ]
    }
   ],
   "source": [
    "with open(src_file) as src:\n",
    "      # print(type(src))\n",
    "      if src.crs is not None:\n",
    "            src_crs = src.crs\n",
    "            print(\"Detected source crs : \", src_crs)\n",
    "      else: \n",
    "            src_crs = 'EPSG:4326'\n",
    "            print(\"Assuming source crs : \", src_crs)\n",
    "\n",
    "      if len(src.nodatavals)>1:\n",
    "            nodata = src.nodatavals[0]\n",
    "      else :\n",
    "            nodata = src.nodatavals\n",
    "\n",
    "      print(\"No data value : \", nodata)      \n",
    "            # At this point 'vrt' is a full dataset with dimensions,\n",
    "            # CRS, and spatial extent matching 'vrt_options'.\n",
    "            # Read all data into memory.\n",
    "            # data = vrt.read()\n",
    "            # Process the dataset in chunks.  Likely not very efficient.\n",
    "\n",
    "      \n",
    "\n",
    "      read_lock = threading.Lock() # not necessary ?\n",
    "      # write_lock = threading.Lock()\n",
    "      \n",
    "      readers = [WarpedVRT(src, **vrt_options) for i in range(num_workers)]\n",
    "      \n",
    "      windows = [window for ij, window in readers[0].block_windows()]\n",
    "\n",
    "      writers = [ParquetWriter(out_file, rast_schema) for out_file in out_files]\n",
    "\n",
    "      # for w in writers:\n",
    "      #       w.write(Table.from_pandas(df=pd.DataFrame(data={\"lon\" : [1.0,2.0,3.0],\"lat\" : [4.0,5.0,6.0],\"band_var\" : np.random.random(3)}),schema = rast_schema))\n",
    "      # for w in writers:\n",
    "      #       w.close()\n",
    "      # raise Warning\n",
    "\n",
    "      def process(writer,vrt,windows):\n",
    "            print(\"Processing!\")\n",
    "            win_transfrom = vrt.window_transform\n",
    "            for window in windows:\n",
    "\n",
    "                  band1 = vrt.read(window=window)\n",
    "                  \n",
    "                  height = band1.shape[1]\n",
    "                  width = band1.shape[2]\n",
    "                  cols, rows = meshgrid(arange(width), arange(height))\n",
    "\n",
    "                  xs, ys = xy(\n",
    "                        transform = win_transfrom(window),\n",
    "                        rows=rows,\n",
    "                        cols=cols)\n",
    "\n",
    "                  lons = array(xs)\n",
    "                  lats = array(ys)\n",
    "                  \n",
    "                  out = DataFrame({\"band_var\" : array(band1).flatten()\n",
    "                                          ,'lon': lons.flatten()\n",
    "                                          ,'lat': lats.flatten()})\n",
    "                  \n",
    "                  out.drop(index=out.loc[out.band_var==nodata].index,inplace=True)\n",
    "                  if not include:\n",
    "                        out.drop(index=out.loc[out.band_var<=0].index,inplace=True)\n",
    "                  \n",
    "                  if out.shape[0]!=0:\n",
    "                        writer.write_table(Table.from_pandas(df=out,schema = rast_schema,nthreads=1,preserve_index=False,safe=True))\n",
    "\n",
    "      # We map the process() function over the list of\n",
    "      # windows.\n",
    "      with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=num_workers\n",
    "      ) as executor:\n",
    "            # executor.map(process, writers,readers,itertools.batched(windows,num_workers))\n",
    "            for (w,v,win) in zip(writers,readers,itertools.batched(windows,num_workers)):\n",
    "                  executor.submit(process(w,v,win))\n",
    "                  \n",
    "      for w in writers:\n",
    "            w.close()\n",
    "      for vrt in readers:\n",
    "            vrt.close()\n",
    "      # print(writers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rast_convert_1 = ib.read_parquet(out_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────┐\n",
      "│ \u001b[1;36m12\u001b[0m │\n",
      "└────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> lon       </span>┃<span style=\"font-weight: bold\"> lat       </span>┃<span style=\"font-weight: bold\"> band_var </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>  │\n",
       "├───────────┼───────────┼──────────┤\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.003524</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.255964</span> │   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1404.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.000778</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.255051</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275.0</span> │\n",
       "│  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.000138</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.255051</span> │     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.008100</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.251389</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">836.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.007185</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.251389</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">836.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.009015</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.250473</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.019084</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.246813</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.019999</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.245897</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">323.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.019999</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.244982</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255.0</span> │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.019084</span> │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.244982</span> │    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.0</span> │\n",
       "│         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">…</span> │         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">…</span> │        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">…</span> │\n",
       "└───────────┴───────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mlon\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlat\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mband_var\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│ \u001b[2mfloat32\u001b[0m   │ \u001b[2mfloat32\u001b[0m   │ \u001b[2mfloat32\u001b[0m  │\n",
       "├───────────┼───────────┼──────────┤\n",
       "│ \u001b[1;36m-0.003524\u001b[0m │ \u001b[1;36m16.255964\u001b[0m │   \u001b[1;36m1404.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.000778\u001b[0m │ \u001b[1;36m16.255051\u001b[0m │    \u001b[1;36m275.0\u001b[0m │\n",
       "│  \u001b[1;36m0.000138\u001b[0m │ \u001b[1;36m16.255051\u001b[0m │     \u001b[1;36m29.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.008100\u001b[0m │ \u001b[1;36m16.251389\u001b[0m │    \u001b[1;36m836.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.007185\u001b[0m │ \u001b[1;36m16.251389\u001b[0m │    \u001b[1;36m836.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.009015\u001b[0m │ \u001b[1;36m16.250473\u001b[0m │    \u001b[1;36m531.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.019084\u001b[0m │ \u001b[1;36m16.246813\u001b[0m │    \u001b[1;36m167.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.019999\u001b[0m │ \u001b[1;36m16.245897\u001b[0m │    \u001b[1;36m323.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.019999\u001b[0m │ \u001b[1;36m16.244982\u001b[0m │    \u001b[1;36m255.0\u001b[0m │\n",
       "│ \u001b[1;36m-0.019084\u001b[0m │ \u001b[1;36m16.244982\u001b[0m │    \u001b[1;36m242.0\u001b[0m │\n",
       "│         \u001b[2m…\u001b[0m │         \u001b[2m…\u001b[0m │        \u001b[2m…\u001b[0m │\n",
       "└───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rast_convert_1.count())\n",
    "rast_convert_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rast_convert_par = ib.read_parquet(\"rast_convert_par.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rast_convert_par.count())\n",
    "rast_convert_par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.difference(rast_convert_1,rast_convert_par)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
